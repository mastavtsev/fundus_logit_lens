## Что такое Logit Lens?

Logit Lens — это аналитический метод, позволяющий «заглянуть» внутрь нейросетевой языковой (или мультимодальной) модели и отследить, какие токены она предполагает на каждом слое до окончательной генерации. Беря вектор логитов, который модель вычисляет после каждого блока трансформера, и проецируя его в пространство словаря, мы можем посмотреть, какие слова/понятия наиболее вероятны в каждый момент времени. Так удаётся узнать, когда именно модель «приходит к пониманию» определённого факта, и какие внутренние представления к этому ведут.

Применительно к визуально‑языковым моделям (VLM) Logit Lens даёт возможность раскрыть, на каком слое появляется осознание того, что изображено на фотографии.

## О проекте

В течение 2025 года я разрабатывал систему автоматизированного описания глазного дна. На вход она принимала текстовые параметры, вручную извлечённые офтальмологом (окружность диска зрительного нерва, наличие экссудатов и т. д.). Следующий шаг — отказаться от ручного ввода и напрямую использовать снимки. Чтобы оценить потенциал подхода, мы применили Logit Lens к мультимодели Qwen2‑VL и проверили:

Осознаёт ли VLM, что перед ней именно снимок глазного дна?

На каком слое трансформера формируется такое понимание?

Можно ли, зная номер слоя, изъять промежуточные представления и направить их в специализированный декодер для генерации полноценного описания?

Если вывод будет положительным (уже на ранних слоях модель «угадывает» концепт fundus photo), это открывает дорогу к дальнейшему исследованию: построению надстройки, которая автоматически генерирует протокол описания глазного дна.

## Требования к оборудованию

Запустите ноутбук fundus_base.ipynb в среде с GPU, у которого объём видеопамяти не менее 16 ГБ. Это необходимо, потому что в эксперименте используется визуально‑языковая модель Qwen 2.5‑VL на 7 миллиардов параметров, требующая значительного VRAM.

## Шаги запуска

Склонируйте (или скачайте) содержимое этого репозитория:

git clone <repo‑url>
cd <repo‑folder>

Убедитесь, что в той же директории находятся файлы fundus_base.ipynb и data.zip.

Распакуйте архив данных:

unzip data.zip -d data

Откройте ноутбук в Jupyter/Lab и выполните ячейки сверху вниз.
